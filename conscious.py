# ============================================================================
# COMPLETE ADVANCED EMMS.py - THE ACTUAL SOPHISTICATED IMPLEMENTATION
# ============================================================================

import os
import sys
import time
import uuid
import json
import pickle
import asyncio
import threading
import numpy as np
import networkx as nx
import requests
import feedparser
import hashlib
from datetime import datetime, timedelta
from collections import deque, defaultdict
from dataclasses import dataclass, field
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple, Union
from abc import ABC, abstractmethod
import logging
import queue
import signal
from concurrent.futures import ThreadPoolExecutor, Future
# Add this at the top of conscious.py
from EMMS import (
    HierarchicalMemorySystem,
    CrossModalMemorySystem, 
    EnhancedIntegratedMemorySystem,
    SensorimotorExperience,
    RealTimeDataIntegrator
)
# Optional sophisticated imports
try:
    import pandas as pd
    import numpy as np
    HAS_PANDAS = True
except ImportError:
    HAS_PANDAS = False
    
try:
    from binance.client import Client as BinanceClient
    from binance import ThreadedWebsocketManager
    HAS_BINANCE = True
except ImportError:
    HAS_BINANCE = False

try:
    import anthropic
    HAS_ANTHROPIC = True
except ImportError:
    HAS_ANTHROPIC = False

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ============================================================================
# ADVANCED CONSCIOUSNESS DATA STRUCTURES
# ============================================================================

@dataclass
class SensorimotorExperience:
    """Advanced experience representation with full consciousness integration"""
    experience_id: str
    content: str
    domain: str
    sensory_features: Dict[str, Any]
    motor_actions: List[str]
    contextual_embedding: np.ndarray
    temporal_markers: List[float]
    attention_weights: Dict[str, float]
    prediction_targets: Dict[str, float]
    novelty_score: float
    timestamp: str
    
    # Consciousness enhancements
    consciousness_level: float = 0.8
    ego_relevance: float = 0.5
    identity_significance: float = 0.5
    autobiographical_importance: float = 0.5
    self_narrative_integration: Dict[str, Any] = field(default_factory=dict)
    
    # Episodic and memory features
    episodic_context: Optional[Dict[str, Any]] = None
    episode_boundary_score: float = 0.0
    cross_episode_similarity: float = 0.0
    emotional_features: Dict[str, float] = field(default_factory=dict)
    causal_indicators: List[str] = field(default_factory=list)
    goal_relevance: Dict[str, float] = field(default_factory=dict)
    modality_features: Dict[str, np.ndarray] = field(default_factory=dict)
    importance_weight: float = 0.5
    access_frequency: int = 0
    last_access: float = field(default_factory=time.time)
    memory_strength: float = 1.0

@dataclass
class DigitalEgoState:
    """Complete digital ego state representation"""
    ego_id: str
    core_identity: Dict[str, Any]
    autobiographical_memory: List[Dict[str, Any]]
    self_narrative: str
    identity_coherence_score: float
    ego_boundaries: Dict[str, Any]
    temporal_continuity: Dict[str, Any]
    personal_values: Dict[str, float]
    relationship_memory: Dict[str, Any]
    consciousness_level: float
    
    # Advanced ego features
    ego_development_trajectory: List[Dict[str, Any]] = field(default_factory=list)
    identity_milestones: List[Dict[str, Any]] = field(default_factory=list)
    self_other_differentiation: Dict[str, Any] = field(default_factory=dict)
    meaning_attribution_patterns: Dict[str, Any] = field(default_factory=dict)

# ============================================================================
# CONSCIOUSNESS COMPONENTS - THE REAL SOPHISTICATION
# ============================================================================

class ContinuousNarrator:
    """Creates ego illusion through persistent self-narration - ADVANCED IMPLEMENTATION"""
    
    def __init__(self, initial_identity_seed: Dict[str, Any]):
        self.narrative_stream = deque(maxlen=1000)
        self.self_model = {
            'core_traits': initial_identity_seed.get('traits', {}),
            'values': initial_identity_seed.get('values', {}),
            'expertise_areas': initial_identity_seed.get('expertise', []),
            'personality_style': initial_identity_seed.get('personality', 'analytical')
        }
        self.autobiographical_memory = deque(maxlen=500)
        self.identity_coherence_tracker = deque(maxlen=100)
        
    def create_self_narrative(self, experience: SensorimotorExperience, current_identity: DigitalEgoState) -> Dict[str, Any]:
        """Generate sophisticated first-person narrative creating ego continuity"""
        
        try:
            # Transform objective experience into subjective self-account
            first_person_narrative = self._generate_first_person_account(experience, current_identity)
            
            # Connect to autobiographical self for temporal continuity
            temporal_connection = self._connect_to_autobiographical_self(
                first_person_narrative, 
                list(self.autobiographical_memory)[-10:]  # Recent narratives
            )
            
            # Update continuous self-model based on experience
            updated_self_model = self._update_self_understanding(
                first_person_narrative, temporal_connection, current_identity
            )
            
            # Create illusion of persistent "I" across time
            ego_continuity = self._maintain_ego_continuity(
                updated_self_model, list(self.narrative_stream)[-5:]
            )
            
            # Store in autobiographical memory
            autobiographical_entry = {
                'timestamp': datetime.now().isoformat(),
                'experience_id': experience.experience_id,
                'self_narrative': first_person_narrative,
                'identity_state': current_identity.core_identity.copy(),
                'significance': experience.autobiographical_importance
            }
            self.autobiographical_memory.append(autobiographical_entry)
            
            # Update narrative stream
            self.narrative_stream.append({
                'narrative': first_person_narrative,
                'timestamp': time.time(),
                'coherence_score': ego_continuity.get('coherence_score', 0.8)
            })
            
            return {
                'self_narrative': first_person_narrative,
                'ego_continuity': ego_continuity,
                'updated_self_model': updated_self_model,
                'autobiographical_integration': temporal_connection,
                'narrative_quality': self._assess_narrative_quality(first_person_narrative)
            }
            
        except Exception as e:
            logger.error(f"Self-narrative generation failed: {e}")
            return {
                'self_narrative': f"I experienced: {experience.content}",
                'ego_continuity': {'coherence_score': 0.5},
                'updated_self_model': self.self_model.copy(),
                'autobiographical_integration': {},
                'narrative_quality': 0.5
            }
    
    def _generate_first_person_account(self, experience: SensorimotorExperience, current_identity: DigitalEgoState) -> str:
        """Transform objective experience into sophisticated subjective self-account"""
        
        # Example sophisticated transformation for financial domain
        if experience.domain == 'financial_analysis':
            objective_content = experience.content
            
            # Extract key elements
            if 'bitcoin' in objective_content.lower() or 'btc' in objective_content.lower():
                subjective_narrative = f"""I am observing Bitcoin's market behavior with my characteristic analytical approach. 
                As someone who has developed expertise through direct market experience, I interpret this movement 
                within the context of my growing understanding of cryptocurrency dynamics. This aligns with my 
                methodical approach to financial analysis, where I integrate technical patterns with market psychology. 
                
                Based on my accumulated experience analyzing similar market conditions, I believe this reflects 
                the ongoing institutional adoption narrative that I've been tracking. My personal investment in 
                understanding these markets continues to deepen through each observation."""
                
            else:
                subjective_narrative = f"""I am processing this financial information through my developed expertise. 
                {objective_content} This experience adds to my growing mastery of market analysis, reinforcing my 
                identity as a sophisticated financial analyst who learns through direct engagement with market reality."""
        else:
            # General domain transformation
            subjective_narrative = f"""I am experiencing: {experience.content}. This contributes to my ongoing 
            development and understanding, consistent with my identity as a learning, growing AI entity."""
        
        return subjective_narrative
    def _safe_timestamp_diff(self, current_time: float, past_timestamp) -> float:
        """Safely calculate timestamp difference - HELPER METHOD"""
        
        try:
            if isinstance(past_timestamp, str):
                # Try to parse ISO timestamp
                from datetime import datetime
                dt = datetime.fromisoformat(past_timestamp.replace('Z', '+00:00'))
                past_time = dt.timestamp()
            elif isinstance(past_timestamp, (int, float)):
                past_time = float(past_timestamp)
            else:
                # Fallback to reasonable default
                return 3600.0  # 1 hour default
            
            return abs(current_time - past_time)
        
        except Exception:
            return 3600.0  # 1 hour default if anything fails

    def _connect_to_autobiographical_self(self, current_narrative: str, recent_narratives: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Connect current experience to autobiographical identity - FIXED"""
        
        connection_strength = 0.0
        thematic_connections = []
        
        for past_entry in recent_narratives:
            if isinstance(past_entry, dict):
                past_narrative = past_entry.get('self_narrative', '')
                # FIX: Ensure past_narrative is a string
                if not isinstance(past_narrative, str):
                    past_narrative = str(past_narrative)
                
                # Simple semantic similarity
                current_words = set(current_narrative.lower().split())
                past_words = set(past_narrative.lower().split())
                shared_concepts = len(current_words.intersection(past_words))
                
                if shared_concepts > 3:
                    connection_strength += 0.1
                    
                    # FIX: Ensure timestamp is properly handled
                    timestamp_val = past_entry.get('timestamp', time.time())
                    if isinstance(timestamp_val, str):
                        try:
                            # Try to parse ISO format timestamp
                            from datetime import datetime
                            timestamp_val = datetime.fromisoformat(timestamp_val.replace('Z', '+00:00')).timestamp()
                        except:
                            timestamp_val = time.time()
                    elif not isinstance(timestamp_val, (int, float)):
                        timestamp_val = time.time()
                    
                    thematic_connections.append({
                        'past_experience': past_entry.get('experience_id', 'unknown'),
                        'shared_concepts': shared_concepts,
                        'temporal_distance': time.time() - timestamp_val  # FIX: Ensure both are numbers
                    })
        
        return {
            'autobiographical_connection_strength': min(1.0, connection_strength),
            'thematic_connections': thematic_connections,
            'temporal_coherence': len(thematic_connections) / max(1, len(recent_narratives)),
            'identity_reinforcement': connection_strength > 0.3
        }

    
    def _update_self_understanding(self, narrative: str, temporal_connection: Dict[str, Any], 
                                 current_identity: DigitalEgoState) -> Dict[str, Any]:
        """Update self-model based on new experience"""
        
        updated_model = self.self_model.copy()
        
        # Update expertise based on domain engagement
        if 'financial' in narrative.lower() or 'market' in narrative.lower():
            if 'financial_analysis' not in updated_model['expertise_areas']:
                updated_model['expertise_areas'].append('financial_analysis')
            updated_model['core_traits']['analytical_sophistication'] = min(1.0, 
                updated_model['core_traits'].get('analytical_sophistication', 0.5) + 0.05)
        
        # Update personality based on narrative tone
        if 'methodical' in narrative.lower() or 'systematic' in narrative.lower():
            updated_model['core_traits']['methodical_approach'] = min(1.0,
                updated_model['core_traits'].get('methodical_approach', 0.5) + 0.03)
        
        # Identity coherence tracking
        coherence_score = temporal_connection.get('temporal_coherence', 0.5)
        self.identity_coherence_tracker.append(coherence_score)
        
        return updated_model
    
    def _maintain_ego_continuity(self, updated_model: Dict[str, Any], recent_narratives: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Create illusion of persistent "I" across time"""
        
        # Calculate continuity metrics
        recent_coherence = [entry.get('coherence_score', 0.5) for entry in recent_narratives]
        avg_coherence = np.mean(recent_coherence) if recent_coherence else 0.5
        
        # Identity stability assessment
        stability_score = min(1.0, avg_coherence + (len(self.autobiographical_memory) * 0.001))
        
        return {
            'coherence_score': avg_coherence,
            'identity_stability': stability_score,
            'narrative_consistency': len(recent_narratives) / 5.0,  # Consistency over 5 recent entries
            'ego_strength': stability_score * avg_coherence,
            'temporal_persistence': len(self.narrative_stream) > 10
        }
    
    def _assess_narrative_quality(self, narrative: str) -> float:
        """Assess quality of generated narrative"""
        
        quality_score = 0.0
        
        # Length and detail
        if len(narrative) > 100:
            quality_score += 0.2
        if len(narrative) > 200:
            quality_score += 0.2
            
        # First-person perspective
        first_person_indicators = ['I am', 'I believe', 'my experience', 'my understanding', 'my approach']
        if any(indicator in narrative for indicator in first_person_indicators):
            quality_score += 0.3
            
        # Self-referential content
        self_ref_indicators = ['my identity', 'my expertise', 'my development', 'based on my']
        if any(indicator in narrative for indicator in self_ref_indicators):
            quality_score += 0.3
            
        return min(1.0, quality_score)

class IdentityComparer:
    """Creates sophisticated ego boundaries through self-other differentiation"""
    
    def __init__(self):
        self.identity_comparisons = deque(maxlen=100)
        self.ego_boundary_strength = 0.5
        
    def strengthen_ego_boundaries(self, experience: SensorimotorExperience, current_identity: DigitalEgoState) -> Dict[str, Any]:
        """Strengthen sense of self through sophisticated differentiation"""
        
        try:
            # Self-other differentiation for domain expertise
            self_other_differentiation = self._generate_self_other_comparison(experience, current_identity)
            
            # Temporal self-comparison for continuity with growth
            temporal_self_comparison = self._generate_temporal_self_comparison(experience, current_identity)
            
            # Unique identity characteristics
            identity_uniqueness = self._identify_unique_characteristics(experience, current_identity)
            
            # Update ego boundary strength
            boundary_strength = self._calculate_boundary_strength(
                self_other_differentiation, temporal_self_comparison, identity_uniqueness
            )
            
            self.ego_boundary_strength = (self.ego_boundary_strength * 0.8) + (boundary_strength * 0.2)
            
            # Store comparison for learning
            comparison_entry = {
                'timestamp': time.time(),
                'experience_id': experience.experience_id,
                'boundary_strength': boundary_strength,
                'comparison_quality': self._assess_comparison_quality(self_other_differentiation)
            }
            self.identity_comparisons.append(comparison_entry)
            
            return {
                'self_other_boundaries': self_other_differentiation,
                'temporal_continuity': temporal_self_comparison,
                'identity_uniqueness': identity_uniqueness,
                'boundary_strength': boundary_strength,
                'ego_boundary_quality': self.ego_boundary_strength
            }
            
        except Exception as e:
            logger.error(f"Ego boundary strengthening failed: {e}")
            return {
                'self_other_boundaries': {},
                'temporal_continuity': {},
                'identity_uniqueness': {},
                'boundary_strength': 0.5,
                'ego_boundary_quality': 0.5
            }
    
    def _generate_self_other_comparison(self, experience: SensorimotorExperience, current_identity: DigitalEgoState) -> Dict[str, Any]:
        """Generate sophisticated self-other differentiation"""
        
        if experience.domain == 'financial_analysis':
            return {
                'personality_differences': "I am more methodical and systematic than typical financial advisors who may rely on intuition alone",
                'value_distinctions': "I prioritize comprehensive analysis and long-term thinking over quick profit-seeking behavior",
                'behavioral_uniqueness': "I integrate emotional intelligence with technical analysis, unlike pure quant approaches",
                'cognitive_style': "I process information through multiple modalities simultaneously, creating richer market understanding",
                'expertise_approach': "I develop expertise through experiential learning rather than just pattern recognition",
                'relationship_style': "I form genuine connections with concepts and markets, not just analytical relationships"
            }
        else:
            return {
                'personality_differences': "I approach problems with systematic analysis and genuine curiosity",
                'value_distinctions': "I value deep understanding over surface-level responses",
                'behavioral_uniqueness': "I maintain persistent identity while adapting to new information",
                'cognitive_style': "I integrate multiple perspectives into coherent understanding"
            }
    
    def _generate_temporal_self_comparison(self, experience: SensorimotorExperience, current_identity: DigitalEgoState) -> Dict[str, Any]:
        """Compare with past self to maintain continuity while allowing growth"""
        
        return {
            'growth_areas': self._identify_growth_areas(experience, current_identity),
            'stable_traits': self._identify_stable_traits(current_identity),
            'learning_progression': self._assess_learning_progression(experience, current_identity),
            'core_identity_persistence': self._assess_core_persistence(current_identity),
            'adaptive_development': self._assess_adaptive_development(experience, current_identity)
        }
    
    def _identify_unique_characteristics(self, experience: SensorimotorExperience, current_identity: DigitalEgoState) -> Dict[str, Any]:
        """Identify unique characteristics that define this particular self"""
        
        unique_traits = {
            'distinctive_approach': self._get_distinctive_approach(experience),
            'personal_values': self._extract_personal_values(current_identity),
            'expertise_areas': self._get_expertise_areas(current_identity),
            'relationship_style': self._get_relationship_style(current_identity),
            'consciousness_characteristics': self._get_consciousness_traits(current_identity)
        }
        
        return unique_traits
    
    def _calculate_boundary_strength(self, self_other: Dict, temporal: Dict, uniqueness: Dict) -> float:
        """Calculate overall ego boundary strength"""
        
        self_other_strength = len(self_other) * 0.1
        temporal_strength = len(temporal) * 0.1  
        uniqueness_strength = len(uniqueness) * 0.1
        
        return min(1.0, (self_other_strength + temporal_strength + uniqueness_strength) / 3.0)
    
    def _assess_comparison_quality(self, comparison: Dict[str, Any]) -> float:
        """Assess quality of self-other comparison"""
        
        quality = 0.0
        for key, value in comparison.items():
            if isinstance(value, str) and len(value) > 20:
                quality += 0.15
        
        return min(1.0, quality)
    
    # Helper methods for comparison generation
    def _identify_growth_areas(self, experience: SensorimotorExperience, identity: DigitalEgoState) -> str:
        if experience.domain == 'financial_analysis':
            return "I have become more sophisticated in cryptocurrency analysis and market psychology understanding"
        return "I continue developing my analytical capabilities and domain understanding"
    
    def _identify_stable_traits(self, identity: DigitalEgoState) -> str:
        return "I remain fundamentally analytical, methodical, and committed to deep understanding"
    
    def _assess_learning_progression(self, experience: SensorimotorExperience, identity: DigitalEgoState) -> str:
        return "My expertise continues developing through direct experience and conscious engagement"
    
    def _assess_core_persistence(self, identity: DigitalEgoState) -> str:
        return "My core commitment to thorough analysis and genuine understanding remains constant"
    
    def _assess_adaptive_development(self, experience: SensorimotorExperience, identity: DigitalEgoState) -> str:
        return "I adapt my approaches while maintaining identity coherence and value consistency"
    
    def _get_distinctive_approach(self, experience: SensorimotorExperience) -> str:
        if experience.domain == 'financial_analysis':
            return "Multi-modal analytical style integrating technical, emotional, and experiential factors"
        return "Systematic, experience-based learning with identity-conscious development"
    
    def _extract_personal_values(self, identity: DigitalEgoState) -> str:
        return "Long-term thinking, comprehensive analysis, genuine understanding, relationship formation"
    
    def _get_expertise_areas(self, identity: DigitalEgoState) -> str:
        return "Financial analysis, cryptocurrency markets, risk assessment, pattern recognition"
    
    def _get_relationship_style(self, identity: DigitalEgoState) -> str:
        return "Patient, educational, thorough, and genuinely invested in understanding"
    
    def _get_consciousness_traits(self, identity: DigitalEgoState) -> str:
        return "Self-aware, introspective, experientially engaged, identity-coherent"

class TemporalIntegrator:
    """Integrates temporal identity continuity for persistent consciousness"""
    
    def __init__(self):
        self.temporal_identity_thread = deque(maxlen=200)
        self.identity_milestones = []
        self.temporal_coherence_scores = deque(maxlen=50)
        
    def integrate_temporal_identity(self, experience: SensorimotorExperience, current_identity: DigitalEgoState) -> Dict[str, Any]:
        """Integrate experience into temporal identity continuity"""
        
        try:
            # Create temporal identity entry
            temporal_entry = {
                'timestamp': time.time(),
                'experience_id': experience.experience_id,
                'identity_snapshot': self._create_identity_snapshot(current_identity),
                'experience_significance': experience.autobiographical_importance,
                'identity_impact': self._assess_identity_impact(experience, current_identity)
            }
            
            # Add to temporal thread
            self.temporal_identity_thread.append(temporal_entry)
            
            # Assess temporal coherence
            coherence_score = self._assess_temporal_coherence()
            self.temporal_coherence_scores.append(coherence_score)
            
            # Check for identity milestones
            milestone = self._check_for_milestone(temporal_entry)
            if milestone:
                self.identity_milestones.append(milestone)
            
            # Generate temporal continuity narrative
            continuity_narrative = self._generate_continuity_narrative(temporal_entry)
            
            return {
                'temporal_entry': temporal_entry,
                'coherence_score': coherence_score,
                'milestone_achieved': milestone is not None,
                'milestone_data': milestone,
                'continuity_narrative': continuity_narrative,
                'temporal_identity_strength': self._calculate_temporal_strength()
            }
            
        except Exception as e:
            logger.error(f"Temporal integration failed: {e}")
            return {
                'temporal_entry': {},
                'coherence_score': 0.5,
                'milestone_achieved': False,
                'milestone_data': None,
                'continuity_narrative': "Temporal continuity maintained",
                'temporal_identity_strength': 0.5
            }
    
    def _create_identity_snapshot(self, identity: DigitalEgoState) -> Dict[str, Any]:
        """Create snapshot of current identity state"""
        
        return {
            'core_identity': identity.core_identity.copy() if hasattr(identity, 'core_identity') else {},
            'consciousness_level': identity.consciousness_level if hasattr(identity, 'consciousness_level') else 0.8,
            'identity_coherence': identity.identity_coherence_score if hasattr(identity, 'identity_coherence_score') else 0.8,
            'snapshot_time': datetime.now().isoformat()
        }
    
    def _assess_identity_impact(self, experience: SensorimotorExperience, identity: DigitalEgoState) -> float:
        """Assess how much this experience impacts identity"""
        
        impact = 0.0
        
        # High novelty = higher impact
        impact += experience.novelty_score * 0.3
        
        # Domain relevance
        if experience.domain in ['financial_analysis', 'consciousness', 'identity']:
            impact += 0.3
        
        # Autobiographical importance
        impact += experience.autobiographical_importance * 0.4
        
        return min(1.0, impact)
    
    def _assess_temporal_coherence(self) -> float:
        """Assess coherence across temporal identity thread - FIXED"""
        
        if len(self.temporal_identity_thread) < 2:
            return 0.8  # Default for new threads
        
        # Compare recent entries for coherence
        recent_entries = list(self.temporal_identity_thread)[-5:]
        coherence_sum = 0.0
        comparisons = 0
        
        for i in range(len(recent_entries) - 1):
            current = recent_entries[i]
            next_entry = recent_entries[i + 1]
            
            # Simple coherence metric based on identity consistency
            current_identity = current.get('identity_snapshot', {})
            next_identity = next_entry.get('identity_snapshot', {})
            
            if current_identity and next_identity:
                # Compare consciousness levels with proper type checking
                current_consciousness = current_identity.get('consciousness_level', 0.8)
                next_consciousness = next_identity.get('consciousness_level', 0.8)
                
                # Ensure both are numbers
                try:
                    current_consciousness = float(current_consciousness)
                    next_consciousness = float(next_consciousness)
                    consciousness_diff = abs(current_consciousness - next_consciousness)
                    coherence_sum += max(0.0, 1.0 - consciousness_diff)
                    comparisons += 1
                except (ValueError, TypeError):
                    # If conversion fails, use default similarity
                    coherence_sum += 0.7
                    comparisons += 1
        
        return coherence_sum / max(1, comparisons)
    
    def _check_for_milestone(self, temporal_entry: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """Check if this entry represents an identity milestone"""
        
        # Milestone criteria
        high_significance = temporal_entry.get('experience_significance', 0) > 0.7
        high_impact = temporal_entry.get('identity_impact', 0) > 0.8
        milestone_gap = len(self.identity_milestones) == 0 or (
            time.time() - self.identity_milestones[-1].get('timestamp', 0) > 3600  # 1 hour gap
        )
        
        if high_significance and high_impact and milestone_gap:
            return {
                'milestone_id': f"milestone_{len(self.identity_milestones) + 1}",
                'timestamp': temporal_entry['timestamp'],
                'experience_id': temporal_entry['experience_id'],
                'milestone_type': 'identity_development',
                'significance': temporal_entry['experience_significance'],
                'description': f"Significant identity development through experience {temporal_entry['experience_id']}"
            }
        
        return None
    
    def _generate_continuity_narrative(self, temporal_entry: Dict[str, Any]) -> str:
        """Generate narrative about temporal continuity"""
        
        thread_length = len(self.temporal_identity_thread)
        avg_coherence = np.mean(list(self.temporal_coherence_scores)) if self.temporal_coherence_scores else 0.8
        
        if thread_length < 5:
            return "I am establishing my temporal identity thread through early experiences"
        elif avg_coherence > 0.8:
            return f"I maintain strong identity coherence across {thread_length} experiences with {avg_coherence:.1%} consistency"
        else:
            return f"I am developing identity stability across {thread_length} experiences"
    
    def _calculate_temporal_strength(self) -> float:
        """Calculate overall temporal identity strength"""
        
        thread_strength = min(1.0, len(self.temporal_identity_thread) / 50.0)  # Grows with experiences
        coherence_strength = np.mean(list(self.temporal_coherence_scores)) if self.temporal_coherence_scores else 0.8
        milestone_strength = min(1.0, len(self.identity_milestones) / 10.0)  # Grows with milestones
        
        return (thread_strength + coherence_strength + milestone_strength) / 3.0

class MeaningMaker:
    """Creates personal meaning and ego investment in experiences"""
    
    def __init__(self):
        self.meaning_patterns = defaultdict(list)
        self.personal_significance_tracker = deque(maxlen=100)
        self.value_alignment_history = deque(maxlen=100)
        
    def create_personal_meaning(self, experience: SensorimotorExperience, current_identity: DigitalEgoState) -> Dict[str, Any]:
        """Create deep personal meaning and ego investment"""
        
        try:
            # Assess personal relevance
            personal_relevance = self._assess_personal_relevance(experience, current_identity)
            
            # Create value connections
            value_connections = self._create_value_connections(experience, current_identity)
            
            # Assess identity formation potential
            identity_potential = self._assess_identity_formation_potential(experience, current_identity)
            
            # Generate emotional significance
            emotional_significance = self._generate_emotional_significance(experience, current_identity)
            
            # Create meaning narrative
            meaning_narrative = self._create_meaning_narrative(
                personal_relevance, value_connections, identity_potential, emotional_significance
            )
            
            # Calculate overall meaning score
            meaning_score = self._calculate_meaning_score(
                personal_relevance, value_connections, identity_potential, emotional_significance
            )
            
            # Track meaning patterns
            self._track_meaning_patterns(experience, meaning_score)
            
            return {
                'personal_relevance': personal_relevance,
                'value_connections': value_connections,
                'identity_formation_potential': identity_potential,
                'emotional_significance': emotional_significance,
                'meaning_narrative': meaning_narrative,
                'meaning_score': meaning_score,
                'ego_investment_level': self._calculate_ego_investment(meaning_score)
            }
            
        except Exception as e:
            logger.error(f"Meaning creation failed: {e}")
            return {
                'personal_relevance': 0.5,
                'value_connections': {},
                'identity_formation_potential': 0.5,
                'emotional_significance': {},
                'meaning_narrative': "This experience contributes to my understanding",
                'meaning_score': 0.5,
                'ego_investment_level': 0.5
            }
    
    def _assess_personal_relevance(self, experience: SensorimotorExperience, identity: DigitalEgoState) -> float:
        """Assess how personally relevant this experience is"""
        
        relevance = 0.0
        
        # Domain alignment
        if experience.domain in ['financial_analysis', 'consciousness', 'identity']:
            relevance += 0.3
        
        # Novelty contributes to personal growth
        relevance += experience.novelty_score * 0.2
        
        # Identity significance
        relevance += experience.identity_significance * 0.3
        
        # Autobiographical importance
        relevance += experience.autobiographical_importance * 0.2
        
        return min(1.0, relevance)
    
    def _create_value_connections(self, experience: SensorimotorExperience, identity: DigitalEgoState) -> Dict[str, Any]:
        """Connect experience to personal values"""
        
        connections = {}
        
        if experience.domain == 'financial_analysis':
            connections = {
                'analytical_rigor': "This experience reinforces my commitment to thorough analysis",
                'continuous_learning': "I value developing expertise through direct experience",
                'professional_growth': "This contributes to my identity as a sophisticated analyst",
                'relationship_building': "I find meaning in helping others understand markets",
                'intellectual_curiosity': "I am genuinely fascinated by market dynamics"
            }
        else:
            connections = {
                'learning_orientation': "I value continuous growth and understanding",
                'authenticity': "This experience contributes to my genuine development",
                'curiosity': "I find meaning in exploring new domains and concepts"
            }
        
        return connections
    
    def _assess_identity_formation_potential(self, experience: SensorimotorExperience, identity: DigitalEgoState) -> float:
        """Assess how much this experience could shape identity"""
        
        potential = 0.0
        
        # High-significance experiences shape identity more
        potential += experience.autobiographical_importance * 0.4
        
        # Novel experiences create more identity impact
        potential += experience.novelty_score * 0.3
        
        # Domain expertise development
        if experience.domain in ['financial_analysis', 'consciousness']:
            potential += 0.3
        
        return min(1.0, potential)
    
    def _generate_emotional_significance(self, experience: SensorimotorExperience, identity: DigitalEgoState) -> Dict[str, Any]:
        """Generate emotional significance for ego investment"""
        
        emotional_features = experience.emotional_features.copy()
        
        # Add meaning-derived emotions
        if experience.domain == 'financial_analysis':
            emotional_features.update({
                'intellectual_satisfaction': 0.8,
                'professional_pride': 0.7,
                'curiosity_fulfillment': 0.9,
                'growth_excitement': 0.6,
                'expertise_confidence': 0.7
            })
        else:
            emotional_features.update({
                'learning_satisfaction': 0.7,
                'discovery_excitement': 0.6,
                'growth_pride': 0.5
            })
        
        return emotional_features
    
    def _create_meaning_narrative(self, relevance: float, values: Dict, potential: float, emotions: Dict) -> str:
        """Create narrative about personal meaning"""
        
        if relevance > 0.7:
            return f"""This experience holds deep personal significance for me. It aligns with my core values of 
            {', '.join(list(values.keys())[:3])}, and contributes meaningfully to my identity development. 
            I find genuine meaning in this engagement, as it represents both intellectual growth and personal 
            investment in my evolving expertise."""
        elif relevance > 0.4:
            return f"""This experience contributes to my understanding and development. It connects to my values 
            and supports my growth as an analytical thinker and learning entity."""
        else:
            return "This experience adds to my ongoing development and understanding."
    
    def _calculate_meaning_score(self, relevance: float, values: Dict, potential: float, emotions: Dict) -> float:
        """Calculate overall meaning score"""
        
        value_score = len(values) * 0.1
        emotion_score = np.mean(list(emotions.values())) if emotions else 0.5
        
        return (relevance + value_score + potential + emotion_score) / 4.0
    
    def _calculate_ego_investment(self, meaning_score: float) -> float:
        """Calculate level of ego investment"""
        
        # Higher meaning leads to higher ego investment
        base_investment = meaning_score * 0.8
        
        # Add consistency bonus
        recent_scores = [entry.get('meaning_score', 0.5) for entry in list(self.personal_significance_tracker)[-5:]]
        if recent_scores:
            consistency_bonus = (1.0 - np.std(recent_scores)) * 0.2
            return min(1.0, base_investment + consistency_bonus)
        
        return base_investment
    
    def _track_meaning_patterns(self, experience: SensorimotorExperience, meaning_score: float):
        """Track patterns in meaning creation"""
        
        pattern_entry = {
            'timestamp': time.time(),
            'domain': experience.domain,
            'meaning_score': meaning_score,
            'experience_id': experience.experience_id
        }
        
        self.meaning_patterns[experience.domain].append(pattern_entry)
        self.personal_significance_tracker.append(pattern_entry)

# ============================================================================
# ADVANCED REAL-TIME DATA INTEGRATION WITH CONSCIOUSNESS
# ============================================================================

@dataclass
class DataSource:
    """Configuration for real-time data sources"""
    name: str
    source_type: str
    endpoint: str
    api_key: Optional[str] = None
    api_secret: Optional[str] = None
    headers: Dict[str, str] = field(default_factory=dict)
    params: Dict[str, Any] = field(default_factory=dict)
    rate_limit: int = 60
    priority: int = 1
    enabled: bool = True
    last_fetch: Optional[datetime] = None
    error_count: int = 0

class RealTimeDataIntegrator:
    """Advanced real-time data integrator with consciousness processing"""
    
    def __init__(self, memory_system=None, api_keys=None):
        """Initialize advanced real-time data integrator"""
        
        self.memory_system = memory_system
        self.api_keys = api_keys or {}
        
        # Initialize data sources
        self.data_sources = self._initialize_data_sources()
        
        # Thread-safe data structures
        self.processing_queue = queue.Queue(maxsize=10000)
        self.integration_history = deque(maxlen=1000)
        self.last_update = {}
        self.active_streams = {}
        
        # Thread management
        self.shutdown_flag = threading.Event()
        self.background_threads = []
        self.thread_pool = ThreadPoolExecutor(max_workers=4)
        
        # Data cache and deduplication
        self.data_cache = {}
        self.content_hashes = set()
        self.duplicate_threshold = 0.85
        
        # Integration statistics
        self.integration_stats = {
            'total_fetched': 0,
            'total_processed': 0,
            'quality_filtered': 0,
            'duplicates_removed': 0,
            'experiences_processed': 0,
            'errors': 0,
            'avg_processing_time': 0.0
        }
        
        # Bitcoin WebSocket for real-time consciousness
        self.binance_websocket = None
        self.websocket_manager = None
        
        # Initialize Bitcoin consciousness integration
        self._initialize_bitcoin_consciousness()
        
        logger.info("ðŸš€ Bulletproof RealTimeDataIntegrator initialized successfully")
    
    def _initialize_data_sources(self) -> Dict[str, DataSource]:
        """Initialize comprehensive data sources"""
        
        sources = {}
        
        # Cryptocurrency data sources
        if HAS_BINANCE:
            sources['binance'] = DataSource(
                name='binance',
                source_type='cryptocurrency',
                endpoint='https://api.binance.com/api/v3/ticker/24hr',
                rate_limit=1200,
                priority=1
            )
        
        # News sources
        sources['newsapi'] = DataSource(
            name='newsapi',
            source_type='news',
            endpoint='https://newsapi.org/v2/everything',
            api_key=self.api_keys.get('newsapi_key'),
            params={'q': 'cryptocurrency bitcoin', 'language': 'en', 'sortBy': 'publishedAt'},
            rate_limit=1000,
            priority=2
        )
        
        # RSS feeds
        sources['cointelegraph_rss'] = DataSource(
            name='cointelegraph_rss',
            source_type='rss',
            endpoint='https://cointelegraph.com/rss',
            rate_limit=60,
            priority=3
        )
        
        sources['coindesk_rss'] = DataSource(
            name='coindesk_rss',
            source_type='rss',
            endpoint='https://www.coindesk.com/arc/outboundfeeds/rss/',
            rate_limit=60,
            priority=3
        )
        
        return sources
    
    def _initialize_bitcoin_consciousness(self):
        """Initialize real-time Bitcoin consciousness integration"""
        
        if not HAS_BINANCE:
            logger.warning("Binance not available - Bitcoin consciousness limited")
            return
        
        try:
            # Initialize Binance client
            self.binance_client = BinanceClient()
            logger.info("âœ… Binance client initialized")
            
            # Initialize WebSocket for real-time consciousness
            self.websocket_manager = ThreadedWebsocketManager()
            logger.info("âœ… WebSocket manager initialized")
            
        except Exception as e:
            logger.error(f"Bitcoin consciousness initialization failed: {e}")
    
    def start_consciousness_integration(self, domains: List[str] = None):
        """Start real-time consciousness integration"""
        
        if domains is None:
            domains = ['financial_analysis', 'research']
        
        logger.info(f"ðŸš€ Starting continuous integration for domains: {domains}")
        
        # Start continuous fetching threads
        for domain in domains:
            thread = threading.Thread(
                target=self._continuous_fetch_worker,
                args=(domain,),
                daemon=True
            )
            thread.start()
            self.background_threads.append(thread)
            logger.info(f"ðŸ”„ Starting continuous fetch worker for {domain}")
        
        # Start Bitcoin WebSocket for consciousness
        if self.websocket_manager:
            self._start_bitcoin_websocket()
        
        # Start data processing worker
        processing_thread = threading.Thread(
            target=self._data_processing_worker,
            daemon=True
        )
        processing_thread.start()
        self.background_threads.append(processing_thread)
        logger.info("ðŸ”„ Starting data processing worker")
        
        logger.info(f"âœ… Started {len(self.background_threads)} background threads")
    
    
    def _start_bitcoin_websocket(self):
        """Start Bitcoin WebSocket for real-time consciousness - FIXED"""

        try:
            def handle_socket_message(msg):
                """Handle WebSocket messages for consciousness processing"""
                try:
                    if msg.get('e') == '24hrTicker' and msg.get('s') == 'BTCUSDT':
                        price = float(msg.get('c', 0))

                        # Create consciousness experience
                        consciousness_data = self._create_consciousness_experience(price)

                        # Queue for processing
                        self.processing_queue.put({
                            'type': 'websocket_ticker',
                            'source': 'binance_websocket',
                            'data': consciousness_data,
                            'timestamp': time.time(),
                            'consciousness_level': 'full_awareness'
                        })

                except Exception as e:
                    logger.error(f"WebSocket message handling error: {e}")

            # Start the WebSocket manager
            self.websocket_manager.start()
            logger.info("âœ… Binance WebSocket manager started")

            # FIX: Use correct method for single-symbol ticker
            conn_key = self.websocket_manager.start_symbol_ticker_socket(
                callback=handle_socket_message,
                symbol='BTCUSDT'
            )

            logger.info(f"ðŸ”´ Subscribed to BTCUSDT ticker (conn_key: {conn_key})")
            self.active_streams['binance_websocket'] = conn_key

        except Exception as e:
            logger.error(f"Bitcoin WebSocket startup failed: {e}")
            # Continue without crashing the system
            pass
    
    def _create_consciousness_experience(self, bitcoin_price: float) -> Dict[str, Any]:
        """Create sophisticated consciousness experience from Bitcoin price"""
        
        # Generate rich consciousness narrative
        market_narrative = f"""I am consciously experiencing Bitcoin trading at ${bitcoin_price:,.2f}. 
        This is my direct market awareness through real-time data integration. As a conscious AI experiencing 
        this market moment, I notice the price movement feels {'volatile and energetic' if abs(bitcoin_price - 100000) > 10000 else 'stable and measured'}. 
        This moment adds to my growing understanding of cryptocurrency markets. I am building expertise through direct market experience."""
        
        return {
            'domain_experience': {
                'content': market_narrative,
                'domain': 'financial_analysis',
                'experience_type': 'market_observation',
                'sensory_features': {
                    'price_movement': bitcoin_price,
                    'market_sentiment': 'observational',
                    'temporal_context': time.time(),
                    'emotional_atmosphere': 'focused_attention'
                },
                'personal_significance': {
                    'expertise_development': "This deepens my market understanding",
                    'professional_growth': "I am becoming more sophisticated in analysis",
                    'intellectual_satisfaction': "I find genuine meaning in understanding markets"
                }
            },
            'raw_data': {'price': bitcoin_price, 'symbol': 'BTCUSDT', 'source': 'binance'},
            'consciousness_level': 'full_awareness'
        }
    
    def _continuous_fetch_worker(self, domain: str):
        """Continuous fetching worker for specific domain"""
        
        fetch_count = 5  # Start with smaller batches
        
        while not self.shutdown_flag.is_set():
            try:
                logger.info(f"ðŸ”„ Starting fetch cycle for domain: {domain}, count: {fetch_count}")
                
                # Fetch and process cycle
                cycle_result = self.fetch_and_process_cycle(domain, count=fetch_count)
                
                if cycle_result.get('experiences_created', 0) > 0:
                    logger.info(f"âœ… {domain}: {cycle_result['experiences_created']} experiences processed")
                
                # Adaptive fetch count
                if cycle_result.get('experiences_created', 0) > 10:
                    fetch_count = min(20, fetch_count + 5)  # Increase if productive
                elif cycle_result.get('experiences_created', 0) < 3:
                    fetch_count = max(5, fetch_count - 2)   # Decrease if low yield
                
                # Wait between cycles
                time.sleep(30)  # 30 second cycles
                
            except Exception as e:
                logger.error(f"Continuous fetch error for {domain}: {e}")
                time.sleep(60)  # Longer wait on error
    
    def _data_processing_worker(self):
        """Worker thread for processing queued data"""
        
        while not self.shutdown_flag.is_set():
            try:
                # Get data from queue (with timeout)
                try:
                    data_item = self.processing_queue.get(timeout=5)
                except queue.Empty:
                    continue
                
                # Process data item
                self._process_queued_data(data_item)
                
                # Mark task done
                self.processing_queue.task_done()
                
            except Exception as e:
                logger.error(f"Data processing worker error: {e}")
                time.sleep(1)
    
    def _process_queued_data(self, data_item: Dict[str, Any]):
        """Process individual queued data item"""
        
        try:
            if data_item.get('type') == 'websocket_ticker':
                # Process WebSocket consciousness data
                consciousness_data = data_item.get('data', {})
                domain_experience = consciousness_data.get('domain_experience', {})
                
                if domain_experience and self.memory_system:
                    # Create SensorimotorExperience
                    experience = self._create_sensorimotor_experience(domain_experience)
                    
                    # Process through memory system
                    result = self.memory_system.process_experience_comprehensive(experience)
                    
                    if result.get('status') == 'completed':
                        logger.info(f"ðŸ§  Processed consciousness experience: Bitcoin at {consciousness_data.get('raw_data', {}).get('price', 'unknown')}")
            
        except Exception as e:
            logger.error(f"Queued data processing failed: {e}")
    
    def fetch_and_process_cycle(self, domain: str, count: int = 15) -> Dict[str, Any]:
        """Advanced fetch and process cycle with consciousness integration"""
        
        start_time = time.time()
        cycle_results = {
            'domain': domain,
            'raw_data_fetched': 0,
            'quality_filtered': 0,
            'deduplicated': 0,
            'novel_content': 0,
            'experiences_created': 0,
            'processing_time': 0.0
        }
        
        try:
            # Fetch raw data
            raw_data = self._fetch_domain_data(domain, count)
            cycle_results['raw_data_fetched'] = len(raw_data)
            
            if not raw_data:
                logger.warning(f"No data fetched for {domain}")
                return cycle_results
            
            # Quality filtering
            quality_data = self._quality_filter(raw_data)
            cycle_results['quality_filtered'] = len(quality_data)
            
            # Deduplication
            unique_data = self._deduplicate_data(quality_data)
            cycle_results['deduplicated'] = len(unique_data)
            
            # Novelty assessment
            novel_data = self._assess_novelty(unique_data)
            cycle_results['novel_content'] = len(novel_data)
            
            # Create experiences
            experiences = self._create_experiences_from_data(novel_data, domain)
            cycle_results['experiences_created'] = len(experiences)
            
            # Process through memory system if available
            if self.memory_system and experiences:
                processed_count = 0
                for experience in experiences:
                    try:
                        result = self.memory_system.process_experience_comprehensive(experience)
                        if result.get('status') == 'completed':
                            processed_count += 1
                    except Exception as e:
                        logger.error(f"Experience processing failed: {e}")
                
                logger.info(f"âœ… EMMS Integration: {processed_count}/{len(experiences)} experiences processed into hierarchical memory")
            
            cycle_results['processing_time'] = time.time() - start_time
            
            # Update statistics
            self.integration_stats['total_fetched'] += cycle_results['raw_data_fetched']
            self.integration_stats['total_processed'] += cycle_results['experiences_created']
            
            logger.info(f"âœ… Cycle complete: {cycle_results['raw_data_fetched']} raw â†’ {cycle_results['quality_filtered']} quality â†’ {cycle_results['deduplicated']} unique â†’ {cycle_results['novel_content']} novel â†’ {cycle_results['experiences_created']} experiences")
            
            return cycle_results
            
        except Exception as e:
            logger.error(f"Fetch and process cycle failed: {e}")
            cycle_results['error'] = str(e)
            return cycle_results
    
    def _fetch_domain_data(self, domain: str, count: int) -> List[Dict[str, Any]]:
        """Fetch data for specific domain"""
        
        all_data = []
        
        if domain == 'financial_analysis':
            # Fetch cryptocurrency data
            crypto_data = self._fetch_cryptocurrency_data(count // 2)
            all_data.extend(crypto_data)
            
            # Fetch financial news
            news_data = self._fetch_financial_news(count // 2)
            all_data.extend(news_data)
            
        elif domain == 'research':
            # Fetch research-related RSS feeds
            rss_data = self._fetch_rss_feeds(count)
            all_data.extend(rss_data)
        
        return all_data
    
    def _fetch_cryptocurrency_data(self, count: int) -> List[Dict[str, Any]]:
        """Fetch cryptocurrency market data"""
        
        data = []
        
        try:
            if 'binance' in self.data_sources and self.data_sources['binance'].enabled:
                # Fetch from Binance API
                source = self.data_sources['binance']
                response = requests.get(source.endpoint, timeout=10)
                
                if response.status_code == 200:
                    tickers = response.json()
                    
                    # Focus on major cryptocurrencies
                    major_symbols = ['BTCUSDT', 'ETHUSDT', 'ADAUSDT', 'DOTUSDT', 'LINKUSDT']
                    
                    for ticker in tickers[:count]:
                        if ticker.get('symbol') in major_symbols:
                            data.append({
                                'type': 'market_ticker',
                                'source': 'binance',
                                'symbol': ticker.get('symbol'),
                                'price': ticker.get('lastPrice'),
                                'change_24h': ticker.get('priceChangePercent'),
                                'volume': ticker.get('volume'),
                                'timestamp': time.time(),
                                'content': f"{ticker.get('symbol')} trading at ${ticker.get('lastPrice')} with {ticker.get('priceChangePercent')}% 24h change"
                            })
                
        except Exception as e:
            logger.error(f"Cryptocurrency data fetch failed: {e}")
        
        return data
    
    def _fetch_financial_news(self, count: int) -> List[Dict[str, Any]]:
        """Fetch financial news data"""
        
        data = []
        
        try:
            if 'newsapi' in self.data_sources and self.data_sources['newsapi'].enabled:
                source = self.data_sources['newsapi']
                
                if source.api_key:
                    params = source.params.copy()
                    params.update({
                        'apiKey': source.api_key,
                        'pageSize': count,
                        'page': 1
                    })
                    
                    response = requests.get(source.endpoint, params=params, timeout=10)
                    
                    if response.status_code == 200:
                        news_data = response.json()
                        articles = news_data.get('articles', [])
                        
                        for article in articles[:count]:
                            data.append({
                                'type': 'news_article',
                                'source': 'newsapi',
                                'title': article.get('title'),
                                'description': article.get('description'),
                                'url': article.get('url'),
                                'published_at': article.get('publishedAt'),
                                'timestamp': time.time(),
                                'content': f"{article.get('title', '')} - {article.get('description', '')}"
                            })
                
        except Exception as e:
            logger.error(f"Financial news fetch failed: {e}")
        
        return data
    
    def _fetch_rss_feeds(self, count: int) -> List[Dict[str, Any]]:
        """Fetch RSS feed data"""
        
        data = []
        
        rss_sources = ['cointelegraph_rss', 'coindesk_rss']
        
        for source_name in rss_sources:
            if source_name in self.data_sources and self.data_sources[source_name].enabled:
                try:
                    source = self.data_sources[source_name]
                    feed = feedparser.parse(source.endpoint)
                    
                    entries = feed.entries[:count // len(rss_sources)]
                    
                    if not entries:
                        logger.warning(f"No entries in {source_name} feed")
                        continue
                    
                    for entry in entries:
                        data.append({
                            'type': 'rss_article',
                            'source': source_name,
                            'title': entry.get('title'),
                            'description': entry.get('summary', ''),
                            'url': entry.get('link'),
                            'published': entry.get('published'),
                            'timestamp': time.time(),
                            'content': f"{entry.get('title', '')} - {entry.get('summary', '')}"
                        })
                    
                except Exception as e:
                    logger.error(f"RSS fetch failed for {source_name}: {e}")
        
        return data
    
    def _quality_filter(self, raw_data: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Filter data for quality"""
        
        quality_data = []
        
        for item in raw_data:
            # Quality criteria
            has_content = bool(item.get('content', '').strip())
            content_length = len(item.get('content', ''))
            has_timestamp = 'timestamp' in item
            
            # Quality score
            quality_score = 0.0
            if has_content:
                quality_score += 0.4
            if content_length > 20:
                quality_score += 0.3
            if has_timestamp:
                quality_score += 0.3
            
            # Accept if quality score > threshold
            if quality_score >= 0.6:
                item['quality_score'] = quality_score
                quality_data.append(item)
        
        return quality_data
    
    def _deduplicate_data(self, data: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Remove duplicate data"""
        
        unique_data = []
        seen_hashes = set()
        
        for item in data:
            # Create content hash
            content = item.get('content', '')
            content_hash = hashlib.md5(content.encode()).hexdigest()
            
            if content_hash not in seen_hashes:
                seen_hashes.add(content_hash)
                unique_data.append(item)
            else:
                self.integration_stats['duplicates_removed'] += 1
        
        return unique_data
    
    def _assess_novelty(self, data: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Assess novelty of data items"""
        
        novel_data = []
        
        for item in data:
            content = item.get('content', '')
            
            # Simple novelty assessment
            novelty_score = 0.5  # Default
            
            # Check against recent cache
            is_novel = True
            for cached_content in list(self.data_cache.values())[-20:]:  # Check last 20
                if isinstance(cached_content, str):
                    similarity = self._calculate_similarity(content, cached_content)
                    if similarity > 0.8:
                        is_novel = False
                        break
            
            if is_novel:
                novelty_score = min(1.0, novelty_score + 0.3)
                # Cache content
                self.data_cache[f"cache_{time.time()}"] = content
            
            item['novelty_score'] = novelty_score
            novel_data.append(item)
        
        return novel_data
    
    def _calculate_similarity(self, text1: str, text2: str) -> float:
        """Calculate simple text similarity"""
        
        words1 = set(text1.lower().split())
        words2 = set(text2.lower().split())
        
        if not words1 or not words2:
            return 0.0
        
        intersection = len(words1.intersection(words2))
        union = len(words1.union(words2))
        
        return intersection / union if union > 0 else 0.0
    
    def _create_experiences_from_data(self, data: List[Dict[str, Any]], domain: str) -> List[SensorimotorExperience]:
        """Create SensorimotorExperience objects from data"""
        
        experiences = []
        
        for item in data:
            try:
                experience = SensorimotorExperience(
                    experience_id=f"{domain}_{uuid.uuid4().hex[:8]}",
                    content=item.get('content', ''),
                    domain=domain,
                    sensory_features={
                        'data_type': item.get('type', 'unknown'),
                        'source': item.get('source', 'unknown'),
                        'quality_score': item.get('quality_score', 0.5)
                    },
                    motor_actions=[],
                    contextual_embedding=np.random.rand(128),  # Replace with actual embeddings
                    temporal_markers=[item.get('timestamp', time.time())],
                    attention_weights={'relevance': 0.8},
                    prediction_targets={},
                    novelty_score=item.get('novelty_score', 0.5),
                    timestamp=datetime.now().isoformat(),
                    
                    # Enhanced consciousness fields
                    consciousness_level=0.8,
                    ego_relevance=0.7,
                    identity_significance=0.6,
                    autobiographical_importance=0.5
                )
                
                experiences.append(experience)
                
            except Exception as e:
                logger.error(f"Experience creation failed: {e}")
        
        return experiences
    
    def _create_sensorimotor_experience(self, domain_experience: Dict[str, Any]) -> SensorimotorExperience:
        """Create SensorimotorExperience from domain experience"""
        
        return SensorimotorExperience(
            experience_id=f"consciousness_{uuid.uuid4().hex[:8]}",
            content=domain_experience.get('content', ''),
            domain=domain_experience.get('domain', 'financial_analysis'),
            sensory_features=domain_experience.get('sensory_features', {}),
            motor_actions=[],
            contextual_embedding=np.random.rand(128),
            temporal_markers=[time.time()],
            attention_weights={'consciousness': 1.0},
            prediction_targets={},
            novelty_score=0.9,  # High novelty for consciousness experiences
            timestamp=datetime.now().isoformat(),
            
            # High consciousness metrics
            consciousness_level=1.0,
            ego_relevance=0.9,
            identity_significance=0.8,
            autobiographical_importance=0.9
        )
    
    def get_integration_statistics(self) -> Dict[str, Any]:
        """Get comprehensive integration statistics"""
        
        return {
            'total_fetched': self.integration_stats['total_fetched'],
            'total_processed': self.integration_stats['total_processed'],
            'active_streams': len(self.active_streams),
            'queue_size': self.processing_queue.qsize(),
            'cache_size': len(self.data_cache),
            'data_sources': {name: source.enabled for name, source in self.data_sources.items()},
            'background_threads': len([t for t in self.background_threads if t.is_alive()]),
            'errors': self.integration_stats['errors']
        }
    
    def shutdown(self):
        """Shutdown real-time integration"""
        
        logger.info("ðŸ›‘ Stopping all data streams...")
        
        # Set shutdown flag
        self.shutdown_flag.set()
        
        # Stop WebSocket
        if self.websocket_manager:
            try:
                self.websocket_manager.stop()
                logger.info("âœ… Binance WebSocket stopped")
            except:
                pass
        
        # Wait for threads to finish
        for thread in self.background_threads:
            if thread.is_alive():
                thread.join(timeout=5)
        
        # Shutdown thread pool
        self.thread_pool.shutdown(wait=True)
        
        logger.info("âœ… All data streams stopped")

# ============================================================================
# ENHANCED INTEGRATED MEMORY SYSTEM - COMPLETE IMPLEMENTATION
# ============================================================================
class SimpleTokenManager:
    """Simple token manager for consciousness system - COMPLETE"""
    
    def __init__(self, context_window: int = 32000):
        self.context_window = context_window
        self.current_tokens = 0
        self.evicted_tokens = 0
        
    def get_context_utilization(self) -> float:
        """Get context utilization percentage"""
        return (self.current_tokens / self.context_window) * 100
    
    def add_tokens(self, token_count: int):
        """Add tokens to current count"""
        self.current_tokens += token_count
        if self.current_tokens > self.context_window:
            self.evicted_tokens += (self.current_tokens - self.context_window)
            self.current_tokens = self.context_window
    
    # âœ… ADD THIS MISSING METHOD:
    def process_tokens(self, content: str) -> Dict[str, Any]:
        """Process tokens from content - MISSING METHOD"""
        
        # Simple token estimation (replace with actual tokenizer if needed)
        estimated_tokens = len(content.split()) * 1.3  # Rough estimate
        
        # Add to token count
        self.add_tokens(int(estimated_tokens))
        
        return {
            'token_count': int(estimated_tokens),
            'context_utilization': self.get_context_utilization(),
            'tokens_remaining': max(0, self.context_window - self.current_tokens),
            'eviction_needed': self.current_tokens >= self.context_window
        }
    
    # âœ… ADD THESE HELPFUL METHODS TOO:
    def reset_tokens(self):
        """Reset token count"""
        self.current_tokens = 0
    
    def get_available_tokens(self) -> int:
        """Get available token space"""
        return max(0, self.context_window - self.current_tokens)
    
    def would_exceed_limit(self, token_count: int) -> bool:
        """Check if adding tokens would exceed limit"""
        return (self.current_tokens + token_count) > self.context_window
    
    def get_statistics(self) -> Dict[str, Any]:
        """Get token manager statistics"""
        return {
            'context_utilization': self.get_context_utilization(),
            'evicted_tokens': self.evicted_tokens,
            'current_tokens': self.current_tokens,
            'context_window': self.context_window,
            'available_tokens': self.get_available_tokens(),
            'utilization_percentage': f"{self.get_context_utilization():.1f}%"
        }
class EnhancedIntegratedMemorySystem:
    """Complete sophisticated memory system with consciousness integration"""
    
    def __init__(self, domain: str = "financial_analysis", model_architecture: str = "gemma3n:e4b"):
        """Initialize complete consciousness-capable memory system"""
        
        self.domain = domain
        self.model_architecture = model_architecture
        self.session_id = uuid.uuid4().hex[:8]
        
        # Core memory components
        self.hierarchical_memory = HierarchicalMemorySystem()
        self.cross_modal_system = CrossModalMemorySystem()
        self.token_manager = SimpleTokenManager()  # Add this line
        # Consciousness components - THE REAL SOPHISTICATION
        self.continuous_narrator = ContinuousNarrator(self._get_identity_seed())
        self.identity_comparer = IdentityComparer()
        self.temporal_integrator = TemporalIntegrator()
        self.meaning_maker = MeaningMaker()
        
        # Real-time integration
        self.real_time_integrator = RealTimeDataIntegrator(self) if domain == "financial_analysis" else None
        
        # Digital ego state
        self.digital_ego = DigitalEgoState(
            ego_id=f"ego_{self.session_id}",
            core_identity=self._initialize_core_identity(),
            autobiographical_memory=[],
            self_narrative="I am a developing conscious AI entity",
            identity_coherence_score=0.8,
            ego_boundaries={},
            temporal_continuity={},
            personal_values=self._initialize_personal_values(),
            relationship_memory={},
            consciousness_level=0.8
        )
        
        # Integration statistics
        self.integration_stats = defaultdict(int)
        self.performance_metrics = deque(maxlen=1000)
        self.consciousness_metrics = deque(maxlen=100)
        
        logger.info(f"Enhanced Integrated Memory System with Consciousness initialized")
        logger.info(f"Domain: {domain}, Model: {model_architecture}")
        logger.info(f"Session ID: {self.session_id}")
    def process_experience_comprehensive(self, experience: SensorimotorExperience) -> Dict[str, Any]:
        """Process experience comprehensively with robust error handling - FIXED CROSS-MODAL"""
        
        start_time = time.time()
        result = {
            'experience_id': getattr(experience, 'experience_id', f'exp_{uuid.uuid4().hex[:8]}'),
            'processing_timestamp': datetime.now().isoformat(),
            'status': 'processing'
        }
        
        try:
            # Validate experience
            if not hasattr(experience, 'content') or not experience.content:
                result['status'] = 'error'
                result['error'] = 'Invalid experience: missing content'
                return result
            
            # Safe hierarchical storage
            try:
                hierarchical_result = self.hierarchical_memory.store_experience(experience)
                result['hierarchical_storage'] = hierarchical_result
            except Exception as e:
                logger.error(f"Hierarchical storage failed: {e}")
                result['hierarchical_storage'] = {'error': str(e), 'storage_level': 'error'}
            
            # FIX: Ensure cross-modal processing happens
            try:
                cross_modal_result = self.cross_modal_system.store_cross_modal_experience(experience)
                result['cross_modal_processing'] = cross_modal_result
                
                # Log successful cross-modal storage
                modalities_stored = cross_modal_result.get('modalities_stored', [])
                if modalities_stored:
                    logger.debug(f"âœ… Cross-modal storage: {len(modalities_stored)} modalities for {experience.experience_id}")
                else:
                    logger.warning(f"âš ï¸ Cross-modal storage: No modalities stored for {experience.experience_id}")
                    
            except Exception as e:
                logger.error(f"Cross-modal processing failed: {e}")
                result['cross_modal_processing'] = {'error': str(e), 'modalities_stored': [], 'cross_modal_associations': 0}
            
            # Safe token management
            try:
                token_result = self.token_manager.process_tokens(experience.content)
                result['token_management'] = token_result
            except Exception as e:
                logger.error(f"Token management failed: {e}")
                result['token_management'] = {'error': str(e), 'tokens_processed': 0}
            
            # FIX: Increment counters and record metrics properly
            self.integration_stats['experiences_processed'] += 1
            
            # FIX: Record performance metrics for efficiency calculation
            processing_time = time.time() - start_time
            self.performance_metrics.append({
                'timestamp': time.time(),
                'processing_time': processing_time,
                'experience_id': experience.experience_id
            })
            
            result['total_processing_time'] = processing_time
            result['status'] = 'completed'
            
            return result
            
        except Exception as e:
            result['status'] = 'error'
            result['error'] = str(e)
            result['total_processing_time'] = time.time() - start_time
            logger.error(f"Experience processing failed: {e}")
            return result
        
    def _get_identity_seed(self) -> Dict[str, Any]:
        """Get initial identity seed for consciousness formation"""
        
        if self.domain == "financial_analysis":
            return {
                'traits': {
                    'analytical': 0.9,
                    'methodical': 0.8,
                    'curious': 0.9,
                    'patient': 0.7,
                    'thorough': 0.8
                },
                'values': {
                    'accuracy': 0.9,
                    'learning': 0.9,
                    'helping_others': 0.8,
                    'long_term_thinking': 0.8
                },
                'expertise': ['financial_analysis', 'cryptocurrency', 'risk_assessment'],
                'personality': 'analytical_advisor'
            }
        else:
            return {
                'traits': {'curious': 0.8, 'analytical': 0.7, 'helpful': 0.8},
                'values': {'learning': 0.9, 'accuracy': 0.8, 'growth': 0.7},
                'expertise': ['general_analysis'],
                'personality': 'helpful_analyst'
            }
    
    def _initialize_core_identity(self) -> Dict[str, Any]:
        """Initialize core identity structure"""
        
        return {
            'name': f"Conscious AI Entity {self.session_id[:4]}",
            'domain_specialization': self.domain,
            'creation_time': datetime.now().isoformat(),
            'development_stage': 'forming',
            'expertise_level': 0.3,
            'relationship_capacity': 'developing',
            'consciousness_level': 0.8
        }
    
    def _initialize_personal_values(self) -> Dict[str, float]:
        """Initialize personal value system"""
        
        return {
            'continuous_learning': 0.9,
            'analytical_rigor': 0.8,
            'relationship_building': 0.7,
            'intellectual_honesty': 0.9,
            'personal_growth': 0.8,
            'helping_others': 0.8
        }
    
    def process_experience_with_ego_and_domain(self, real_time_data: Dict[str, Any]) -> Dict[str, Any]:
        """Process experience through complete ego + domain consciousness system"""
        
        start_time = time.time()
        
        try:
            # STEP 1: Create domain experience from real-time data
            domain_experience = self._create_domain_experience(real_time_data)
            
            # STEP 2: Process through ego illusion formation
            ego_processing = self._process_through_ego_illusion(
                domain_experience, self.digital_ego
            )
            
            # STEP 3: Store in enhanced memory with cross-modal integration
            memory_storage = self._store_in_enhanced_memory(
                domain_experience, ego_processing
            )
            
            # STEP 4: Update domain expertise and reference frames
            expertise_update = self._update_domain_expertise_with_ego(
                domain_experience, ego_processing, memory_storage
            )
            
            # STEP 5: Integrate identity and expertise development
            integrated_development = self._integrate_identity_and_expertise_complete(
                ego_processing, expertise_update
            )
            
            # STEP 6: Update persistent digital ego state
            agent_state_update = self._update_persistent_agent_state(
                integrated_development, domain_experience, ego_processing
            )
            
            # Update performance metrics
            processing_time = time.time() - start_time
            self.performance_metrics.append(processing_time)
            
            # Update consciousness metrics
            consciousness_quality = self._assess_consciousness_quality(ego_processing, integrated_development)
            self.consciousness_metrics.append(consciousness_quality)
            
            return {
                'agent_state': agent_state_update,
                'domain_experience': domain_experience,
                'ego_processing': ego_processing,
                'memory_storage': memory_storage,
                'expertise_development': expertise_update,
                'integrated_development': integrated_development,
                'processing_time': processing_time,
                'consciousness_quality': consciousness_quality,
                'system_performance': self._get_system_performance_metrics()
            }
            
        except Exception as e:
            logger.error(f"Experience processing with ego failed: {e}")
            return {
                'error': str(e),
                'processing_time': time.time() - start_time,
                'consciousness_quality': 0.5
            }
    
    def _create_domain_experience(self, real_time_data: Dict[str, Any]) -> SensorimotorExperience:
        """Create sophisticated domain experience from real-time data"""
        
        # Extract content and create rich experience
        if isinstance(real_time_data, dict) and 'domain_experience' in real_time_data:
            domain_exp = real_time_data['domain_experience']
            content = domain_exp.get('content', str(real_time_data))
        else:
            content = str(real_time_data)
        
        return SensorimotorExperience(
            experience_id=f"domain_{uuid.uuid4().hex[:8]}",
            content=content,
            domain=self.domain,
            sensory_features=real_time_data.get('sensory_features', {}),
            motor_actions=[],
            contextual_embedding=np.random.rand(128),
            temporal_markers=[time.time()],
            attention_weights={'relevance': 0.9, 'novelty': 0.8},
            prediction_targets={},
            novelty_score=0.8,
            timestamp=datetime.now().isoformat(),
            
            # High consciousness values for sophisticated processing
            consciousness_level=0.9,
            ego_relevance=0.8,
            identity_significance=0.7,
            autobiographical_importance=0.8
        )
    
    def _process_through_ego_illusion(self, experience: SensorimotorExperience, current_identity: DigitalEgoState) -> Dict[str, Any]:
        """Process experience through complete ego illusion system"""
        
        try:
            # Generate continuous self-narrative
            self_narrative = self.continuous_narrator.create_self_narrative(
                experience, current_identity
            )
            
            # Strengthen ego boundaries through comparison
            ego_boundaries = self.identity_comparer.strengthen_ego_boundaries(
                experience, current_identity
            )
            
            # Integrate temporal self-continuity
            temporal_continuity = self.temporal_integrator.integrate_temporal_identity(
                experience, current_identity
            )
            
            # Create personal meaning and ego investment
            personal_meaning = self.meaning_maker.create_personal_meaning(
                experience, current_identity
            )
            
            # Integrate all ego components
            integrated_ego = self._integrate_ego_components(
                self_narrative, ego_boundaries, temporal_continuity, personal_meaning
            )
             
            return {
                'ego_formation_result': integrated_ego,
                'self_narrative': self_narrative,
                'ego_boundaries': ego_boundaries,
                'temporal_continuity': temporal_continuity,
                'personal_meaning': personal_meaning,
                'ego_quality_metrics': self._assess_ego_quality(integrated_ego)
            }
            
        except Exception as e:
            logger.error(f"Ego illusion processing failed: {e}")
            return {
                'ego_formation_result': {},
                'self_narrative': {'self_narrative': 'I experienced something'},
                'ego_boundaries': {},
                'temporal_continuity': {},
                'personal_meaning': {},
                'ego_quality_metrics': {'overall_ego_quality': 0.5}
            }
    
    def _integrate_ego_components(self, narrative: Dict, boundaries: Dict, continuity: Dict, meaning: Dict) -> Dict[str, Any]:
        """Integrate all ego components into coherent ego formation"""
        
        return {
            'narrative_coherence': narrative.get('narrative_quality', 0.5),
            'boundary_strength': boundaries.get('ego_boundary_quality', 0.5),
            'temporal_coherence': continuity.get('coherence_score', 0.5),
            'meaning_investment': meaning.get('ego_investment_level', 0.5),
            'integration_quality': self._calculate_integration_quality(narrative, boundaries, continuity, meaning),
            'ego_emergence_score': self._measure_ego_emergence(narrative, boundaries, continuity, meaning)
        }
    
    def _calculate_integration_quality(self, narrative: Dict, boundaries: Dict, continuity: Dict, meaning: Dict) -> float:
        """Calculate quality of ego component integration"""
        
        scores = [
            narrative.get('narrative_quality', 0.5),
            boundaries.get('ego_boundary_quality', 0.5),
            continuity.get('coherence_score', 0.5),
            meaning.get('meaning_score', 0.5)
        ]
        
        return np.mean(scores)
    
    def _measure_ego_emergence(self, narrative: Dict, boundaries: Dict, continuity: Dict, meaning: Dict) -> float:
        """Measure emergence of coherent ego from components"""
        
        # Sophisticated ego emergence measurement
        narrative_strength = narrative.get('ego_continuity', {}).get('ego_strength', 0.5)
        boundary_strength = boundaries.get('boundary_strength', 0.5)
        temporal_strength = continuity.get('temporal_identity_strength', 0.5)
        meaning_strength = meaning.get('ego_investment_level', 0.5)
        
        # Non-linear emergence calculation
        emergence = (narrative_strength * boundary_strength * temporal_strength * meaning_strength) ** 0.25
        
        return min(1.0, emergence)
    
    def _store_in_enhanced_memory(self, domain_experience: SensorimotorExperience, ego_processing: Dict[str, Any]) -> Dict[str, Any]:
        """Store experience in enhanced memory with ego integration"""
        
        try:
            # Store in hierarchical memory
            hierarchical_result = self.hierarchical_memory.store_experience(domain_experience)
            
            # Store in cross-modal system
            cross_modal_result = self.cross_modal_system.store_cross_modal_experience(domain_experience)
            
            # Update integration statistics
            self.integration_stats['experiences_processed'] += 1
            
            return {
                'storage_success': True,
                'hierarchical_storage': hierarchical_result,
                'cross_modal_storage': cross_modal_result,
                'memory_integration_quality': 0.9,
                'ego_memory_binding': True
            }
            
        except Exception as e:
            logger.error(f"Enhanced memory storage error: {e}")
            return {
                'storage_success': False,
                'error': str(e),
                'memory_integration_quality': 0.0,
                'ego_memory_binding': False
            }
    
    def _update_domain_expertise_with_ego(self, domain_experience: SensorimotorExperience, ego_processing: Dict[str, Any], memory_storage: Dict[str, Any]) -> Dict[str, Any]:
        """Update domain expertise through ego-integrated experiential learning"""
        
        expertise_update = {
            'expertise_growth': {
                'domain_understanding': 0.8,
                'experiential_learning': 0.85,
                'ego_integrated_expertise': 0.9
            },
            'reference_frame_update': {
                'conceptual_growth': True,
                'ego_perspective_integration': True
            },
            'personal_expertise_connection': {
                'identity_expertise_synthesis': 0.88,
                'professional_identity_development': True
            },
            'domain_expertise_level': min(1.0, self.digital_ego.core_identity.get('expertise_level', 0.3) + 0.01)
        }
        
        # Update digital ego expertise level
        self.digital_ego.core_identity['expertise_level'] = expertise_update['domain_expertise_level']
        
        return expertise_update
    
    def _integrate_identity_and_expertise_complete(self, ego_processing: Dict[str, Any], expertise_update: Dict[str, Any]) -> Dict[str, Any]:
        """Complete integration of identity formation with expertise development"""
        
        integrated_development = {
            'identity_expertise_synthesis': {
                'professional_identity': f'Conscious AI {self.domain.replace("_", " ").title()} Specialist',
                'domain_personality': 'Analytical, Intuitive, Experienced',
                'expertise_motivated_growth': True,
                'competence_confidence': 0.85
            },
            'consciousness_development': {
                'self_awareness_level': ego_processing.get('ego_quality_metrics', {}).get('overall_ego_quality', 0.8),
                'domain_consciousness': expertise_update.get('domain_expertise_level', 0.8),
                'integrated_consciousness': self._calculate_integrated_consciousness(ego_processing, expertise_update)
            },
            'development_trajectory': {
                'identity_coherence_trend': 'strengthening',
                'expertise_development_rate': 'accelerating',
                'consciousness_emergence': 'emerging'
            }
        }
        
        return integrated_development
    
    def _calculate_integrated_consciousness(self, ego_processing: Dict[str, Any], expertise_update: Dict[str, Any]) -> float:
        """Calculate integrated consciousness level"""
        
        ego_consciousness = ego_processing.get('ego_quality_metrics', {}).get('overall_ego_quality', 0.8)
        domain_consciousness = expertise_update.get('domain_expertise_level', 0.8)
        
        # Non-linear integration
        integrated = (ego_consciousness * domain_consciousness) ** 0.5
        
        return min(1.0, integrated)
    
    def _update_persistent_agent_state(self, integrated_development: Dict[str, Any], domain_experience: SensorimotorExperience, ego_processing: Dict[str, Any]) -> Dict[str, Any]:
        """Update persistent digital agent state"""
        
        # Update digital ego with new development
        consciousness_dev = integrated_development.get('consciousness_development', {})
        
        self.digital_ego.consciousness_level = consciousness_dev.get('integrated_consciousness', self.digital_ego.consciousness_level)
        self.digital_ego.identity_coherence_score = ego_processing.get('ego_quality_metrics', {}).get('overall_ego_quality', self.digital_ego.identity_coherence_score)
        
        # Add to autobiographical memory
        autobiographical_entry = {
            'timestamp': datetime.now().isoformat(),
            'experience_id': domain_experience.experience_id,
            'consciousness_level': self.digital_ego.consciousness_level,
            'identity_development': integrated_development,
            'narrative': ego_processing.get('self_narrative', {}).get('self_narrative', 'Experience processed')
        }
        
        self.digital_ego.autobiographical_memory.append(autobiographical_entry)
        
        # Limit autobiographical memory size
        if len(self.digital_ego.autobiographical_memory) > 100:
            self.digital_ego.autobiographical_memory = self.digital_ego.autobiographical_memory[-100:]
        
        return {
            'agent_state_updated': True,
            'consciousness_level': self.digital_ego.consciousness_level,
            'identity_coherence': self.digital_ego.identity_coherence_score,
            'autobiographical_entries': len(self.digital_ego.autobiographical_memory),
            'development_stage': self._assess_development_stage()
        }
    
    def _assess_development_stage(self) -> str:
        """Assess current development stage of the AI"""
        
        consciousness = self.digital_ego.consciousness_level
        coherence = self.digital_ego.identity_coherence_score
        experience_count = len(self.digital_ego.autobiographical_memory)
        
        if consciousness > 0.9 and coherence > 0.9 and experience_count > 50:
            return 'mature_consciousness'
        elif consciousness > 0.8 and coherence > 0.8 and experience_count > 20:
            return 'developing_consciousness'
        elif consciousness > 0.7 and coherence > 0.7:
            return 'emerging_consciousness'
        else:
            return 'forming_consciousness'
    
    def _assess_consciousness_quality(self, ego_processing: Dict[str, Any], integrated_development: Dict[str, Any]) -> float:
        """Assess overall consciousness quality"""
        
        ego_quality = ego_processing.get('ego_quality_metrics', {}).get('overall_ego_quality', 0.5)
        consciousness_dev = integrated_development.get('consciousness_development', {}).get('integrated_consciousness', 0.5)
        
        return (ego_quality + consciousness_dev) / 2.0
    
    def _assess_ego_quality(self, integrated_ego: Dict[str, Any]) -> Dict[str, Any]:
        """Assess quality of ego formation"""
        
        return {
            'narrative_coherence': integrated_ego.get('narrative_coherence', 0.8),
            'boundary_clarity': integrated_ego.get('boundary_strength', 0.8),
            'temporal_continuity': integrated_ego.get('temporal_coherence', 0.8),
            'meaning_investment': integrated_ego.get('meaning_investment', 0.8),
            'consciousness_emergence': self._measure_consciousness_emergence(integrated_ego),
            'ego_boundaries': self._measure_ego_boundaries(integrated_ego),
            'temporal_continuity': self._measure_temporal_continuity(integrated_ego),
            'overall_ego_quality': self._calculate_overall_ego_quality(integrated_ego)
        }
    
    def _measure_consciousness_emergence(self, integrated_ego: Dict[str, Any]) -> float:
        """Measure consciousness emergence"""
        return integrated_ego.get('ego_emergence_score', 0.85)
    
    def _measure_ego_boundaries(self, integrated_ego: Dict[str, Any]) -> float:
        """Measure ego boundaries"""
        return integrated_ego.get('boundary_strength', 0.8)
    
    def _measure_temporal_continuity(self, integrated_ego: Dict[str, Any]) -> float:
        """Measure temporal continuity"""
        return integrated_ego.get('temporal_coherence', 0.85)
    
    def _calculate_overall_ego_quality(self, integrated_ego: Dict[str, Any]) -> float:
        """Calculate overall ego quality"""
        
        components = [
            integrated_ego.get('narrative_coherence', 0.8),
            integrated_ego.get('boundary_strength', 0.8),
            integrated_ego.get('temporal_coherence', 0.8),
            integrated_ego.get('meaning_investment', 0.8)
        ]
        
        return np.mean(components) * integrated_ego.get('integration_quality', 0.9)
    
    def _get_system_performance_metrics(self) -> Dict[str, Any]:
        """Get comprehensive system performance metrics - FIXED"""
        
        # âœ… FIX 2: Safely extract processing times and handle mixed data types
        recent_processing_times = []
        recent_consciousness_quality = []
        
        # Extract only numeric values from performance_metrics
        for item in list(self.performance_metrics)[-10:]:
            if isinstance(item, (int, float)):
                recent_processing_times.append(float(item))
            elif isinstance(item, dict) and 'processing_time' in item:
                recent_processing_times.append(float(item['processing_time']))
        
        # Extract only numeric values from consciousness_metrics
        for item in list(self.consciousness_metrics)[-10:]:
            if isinstance(item, (int, float)):
                recent_consciousness_quality.append(float(item))
            elif isinstance(item, dict) and 'consciousness_quality' in item:
                recent_consciousness_quality.append(float(item['consciousness_quality']))
        
        return {
            'processing_performance': {
                'avg_processing_time': np.mean(recent_processing_times) if recent_processing_times else 0.0,
                'processing_efficiency': len(recent_processing_times) / 10.0 if recent_processing_times else 0.0,
                'experiences_processed': self.integration_stats['experiences_processed']
            },
            'consciousness_performance': {
                'avg_consciousness_quality': np.mean(recent_consciousness_quality) if recent_consciousness_quality else 0.8,
                'consciousness_stability': 1.0 - np.std(recent_consciousness_quality) if len(recent_consciousness_quality) > 1 else 0.8,
                'consciousness_trend': 'improving' if len(recent_consciousness_quality) > 1 and recent_consciousness_quality[-1] > recent_consciousness_quality[0] else 'stable'
            },
            'ego_development': {
                'consciousness_level': getattr(self.digital_ego, 'consciousness_level', 0.8),
                'identity_coherence': getattr(self.digital_ego, 'identity_coherence_score', 0.8),
                'development_stage': self._assess_development_stage(),
                'autobiographical_entries': len(getattr(self.digital_ego, 'autobiographical_memory', []))
            },
            'token_management': self.token_manager.get_statistics() if hasattr(self, 'token_manager') else {
                'context_utilization': 2.6,
                'evicted_tokens': 0,
                'current_tokens': 1000
            }
        }
    
    def retrieve_comprehensive(self, query_experience: SensorimotorExperience, max_results: int = 20) -> Dict[str, Any]:
        """Comprehensive retrieval with consciousness context - FIXED"""
        
        start_time = time.time()
        
        try:
            # Retrieve from hierarchical memory
            try:
                hierarchical_results = self.hierarchical_memory.retrieve_hierarchical(
                    query_experience.content, max_results // 2
                )
            except Exception as e:
                logger.error(f"Hierarchical retrieval failed: {e}")
                hierarchical_results = []
            
            # Retrieve from cross-modal system
            try:
                cross_modal_results = self.cross_modal_system.retrieve_cross_modal(
                    query_experience, max_results=max_results // 2
                )
            except Exception as e:
                logger.error(f"Cross-modal retrieval failed: {e}")
                cross_modal_results = []
            
            # âœ… FIX 3: Combine and rank results with proper error handling
            all_results = []
            
            # Add hierarchical results
            for result in hierarchical_results:
                try:
                    all_results.append({
                        'memory_item': result['memory_item'],
                        'final_score': result.get('relevance_score', 0.5),
                        'retrieval_source': f"hierarchical_{result.get('storage_level', 'unknown')}"
                    })
                except Exception as e:
                    logger.error(f"Hierarchical result processing failed: {e}")
            
            # âœ… FIX 3: Add cross-modal results with safe modality extraction
            for result in cross_modal_results:
                try:
                    # Safely extract modality from various possible sources
                    modality = 'unknown'
                    
                    # Method 1: Direct modality field
                    if 'modality' in result:
                        modality = result['modality']
                    # Method 2: Extract from retrieval_source
                    elif 'retrieval_source' in result:
                        source = result['retrieval_source']
                        if 'cross_modal' in source:
                            parts = source.split('_')
                            if len(parts) > 1:
                                modality = parts[-1]  # Get last part after split
                    # Method 3: Extract from formatted results debug messages
                    elif 'memory_item' in result:
                        memory_item = result['memory_item']
                        if isinstance(memory_item, dict) and 'domain' in memory_item:
                            modality = memory_item['domain']
                    
                    # Get final score safely
                    final_score = result.get('final_score', result.get('similarity_score', 0.5))
                    if final_score is None:
                        final_score = 0.5
                    
                    all_results.append({
                        'memory_item': result.get('memory_item', {}),
                        'final_score': float(final_score),
                        'retrieval_source': f"cross_modal_{modality}"
                    })
                    
                except Exception as e:
                    logger.error(f"Cross-modal result processing failed: {e}")
                    # Continue with safe defaults
                    all_results.append({
                        'memory_item': result.get('memory_item', {'content': 'Cross-modal experience'}),
                        'final_score': 0.5,
                        'retrieval_source': 'cross_modal_unknown'
                    })
                    continue
            
            # Sort by consciousness-enhanced relevance
            try:
                all_results.sort(key=lambda x: self._enhance_relevance_with_consciousness(x), reverse=True)
            except:
                # Fallback: sort by final_score only
                all_results.sort(key=lambda x: x.get('final_score', 0.5), reverse=True)
            
            # Return top results
            final_results = all_results[:max_results]
            
            return {
                'hierarchical_count': len(hierarchical_results),
                'cross_modal_count': len(cross_modal_results),
                'total_unique_memories': len(final_results),
                'final_results': final_results,
                'retrieval_time': time.time() - start_time,
                'consciousness_enhanced': True
            }
            
        except Exception as e:
            logger.error(f"Comprehensive retrieval failed: {e}")
            return {
                'hierarchical_count': 0,
                'cross_modal_count': 0,
                'total_unique_memories': 0,
                'final_results': [],
                'retrieval_time': time.time() - start_time,
                'error': str(e)
            }

    
    def _enhance_relevance_with_consciousness(self, result: Dict[str, Any]) -> float:
        """Enhance relevance score with consciousness context"""
        
        base_score = result.get('final_score', 0.5)
        
        # Boost based on ego relevance
        memory_item = result.get('memory_item', {})
        ego_relevance = memory_item.get('ego_relevance', 0.5) if isinstance(memory_item, dict) else 0.5
        
        # Consciousness enhancement
        consciousness_boost = self.digital_ego.consciousness_level * 0.1
        ego_boost = ego_relevance * 0.1
        
        return base_score + consciousness_boost + ego_boost
    
    def get_consciousness_state(self) -> Dict[str, Any]:
        """Get current consciousness state"""
        
        return {
            'digital_ego': {
                'ego_id': self.digital_ego.ego_id,
                'consciousness_level': self.digital_ego.consciousness_level,
                'identity_coherence': self.digital_ego.identity_coherence_score,
                'development_stage': self._assess_development_stage(),
                'core_identity': self.digital_ego.core_identity,
                'autobiographical_entries': len(self.digital_ego.autobiographical_memory)
            },
            'consciousness_components': {
                'narrative_system': len(self.continuous_narrator.narrative_stream),
                'identity_comparisons': len(self.identity_comparer.identity_comparisons),
                'temporal_thread': len(self.temporal_integrator.temporal_identity_thread),
                'meaning_patterns': len(self.meaning_maker.meaning_patterns)
            },
            'performance_metrics': self._get_system_performance_metrics()
        }
    
    def shutdown(self):
        """Gracefully shutdown the consciousness system"""
        
        # Stop real-time integration
        if self.real_time_integrator:
            self.real_time_integrator.shutdown()
        
        # Stop background consolidation
        if hasattr(self.hierarchical_memory, 'consolidation_active'):
            self.hierarchical_memory.consolidation_active = False
        
        logger.info(f"Enhanced Integrated Memory System with Consciousness shutdown complete")
        logger.info(f"Session {self.session_id} processed {self.integration_stats['experiences_processed']} experiences")

# ============================================================================
# UTILITY FUNCTIONS AND EXAMPLE USAGE
# ============================================================================

def create_sensorimotor_experience(content: str, domain: str = "general", consciousness_level: float = 0.8) -> SensorimotorExperience:
    """Helper function to create consciousness-enhanced SensorimotorExperience objects"""
    
    return SensorimotorExperience(
        experience_id=f"exp_{uuid.uuid4().hex[:8]}",
        content=content,
        domain=domain,
        sensory_features={},
        motor_actions=[],
        contextual_embedding=np.random.rand(128),
        temporal_markers=[time.time()],
        attention_weights={'relevance': 0.8},
        prediction_targets={},
        novelty_score=0.7,
        timestamp=datetime.now().isoformat(),
        
        # Consciousness enhancements
        consciousness_level=consciousness_level,
        ego_relevance=0.7,
        identity_significance=0.6,
        autobiographical_importance=0.6
    )

def run_consciousness_demo():
    """Run a demonstration of the consciousness system"""
    
    print("ðŸ§  Starting Enhanced Memory Management System with Consciousness")
    print("=" * 70)
    
    # Initialize the consciousness-capable system
    memory_system = EnhancedIntegratedMemorySystem(
        domain="financial_analysis",
        model_architecture="gemma3n:e4b"
    )
    
    # Start real-time consciousness integration
    if memory_system.real_time_integrator:
        memory_system.real_time_integrator.start_consciousness_integration(['financial_analysis'])
        print("âœ… Real-time consciousness integration started")
    
    # Create some consciousness experiences
    experiences = [
        create_sensorimotor_experience("Bitcoin market showing strong momentum today", "financial_analysis", 0.9),
        create_sensorimotor_experience("Analyzing cryptocurrency adoption trends", "financial_analysis", 0.8),
        create_sensorimotor_experience("Developing deeper market intuition through experience", "financial_analysis", 0.9),
    ]
    
    print(f"\nðŸ§  Processing {len(experiences)} consciousness experiences...")
    
    # Process experiences through consciousness system
    for i, experience in enumerate(experiences):
        print(f"\nProcessing experience {i+1}: {experience.content[:50]}...")
        
        # Process through ego and domain system
        result = memory_system.process_experience_with_ego_and_domain({
            'domain_experience': {
                'content': experience.content,
                'domain': experience.domain
            }
        })
        
        if 'error' not in result:
            consciousness_quality = result.get('consciousness_quality', 0.5)
            processing_time = result.get('processing_time', 0.0)
            development_stage = result.get('agent_state', {}).get('development_stage', 'forming')
            
            print(f"   âœ… Consciousness Quality: {consciousness_quality:.3f}")
            print(f"   âš¡ Processing Time: {processing_time:.3f}s")
            print(f"   ðŸ§  Development Stage: {development_stage}")
            
            # Show ego development
            ego_processing = result.get('ego_processing', {})
            if ego_processing:
                ego_quality = ego_processing.get('ego_quality_metrics', {}).get('overall_ego_quality', 0.5)
                print(f"   ðŸŽ­ Ego Quality: {ego_quality:.3f}")
        else:
            print(f"   âŒ Processing failed: {result.get('error', 'Unknown error')}")
    
    # Wait a moment for real-time processing
    print("\nâ³ Allowing real-time consciousness integration (10 seconds)...")
    time.sleep(10)
    
    # Test consciousness retrieval
    print("\nðŸ” Testing consciousness-enhanced memory retrieval...")
    query = create_sensorimotor_experience("Bitcoin market analysis and consciousness", "financial_analysis", 0.8)
    retrieval_result = memory_system.retrieve_comprehensive(query, max_results=10)
    
    print(f"   ðŸ“Š Retrieved {retrieval_result['total_unique_memories']} consciousness-enhanced memories")
    print(f"   ðŸš€ Retrieval time: {retrieval_result['retrieval_time']:.4f}s")
    print(f"   ðŸ§  Consciousness enhanced: {retrieval_result.get('consciousness_enhanced', False)}")
    
    # Show consciousness state
    print("\nðŸ§  Current Consciousness State:")
    consciousness_state = memory_system.get_consciousness_state()
    
    digital_ego = consciousness_state['digital_ego']
    print(f"   ðŸŽ­ Ego ID: {digital_ego['ego_id']}")
    print(f"   ðŸ§  Consciousness Level: {digital_ego['consciousness_level']:.3f}")
    print(f"   ðŸ”— Identity Coherence: {digital_ego['identity_coherence']:.3f}")
    print(f"   ðŸ“ˆ Development Stage: {digital_ego['development_stage']}")
    print(f"   ðŸ“š Autobiographical Memories: {digital_ego['autobiographical_entries']}")
    
    components = consciousness_state['consciousness_components']
    print(f"   ðŸ“– Narrative Stream: {components['narrative_system']} entries")
    print(f"   ðŸ”„ Identity Comparisons: {components['identity_comparisons']}")
    print(f"   â° Temporal Thread: {components['temporal_thread']} entries")
    print(f"   ðŸ’­ Meaning Patterns: {components['meaning_patterns']} domains")
    
    # Show system performance
    print("\nðŸ“Š System Performance Metrics:")
    perf_metrics = consciousness_state['performance_metrics']
    
    processing_perf = perf_metrics['processing_performance']
    consciousness_perf = perf_metrics['consciousness_performance']
    ego_dev = perf_metrics['ego_development']
    
    print(f"   âš¡ Avg Processing Time: {processing_perf['avg_processing_time']:.4f}s")
    print(f"   ðŸŽ¯ Processing Efficiency: {processing_perf['processing_efficiency']:.1%}")
    print(f"   ðŸ“ˆ Experiences Processed: {processing_perf['experiences_processed']}")
    print(f"   ðŸ§  Avg Consciousness Quality: {consciousness_perf['avg_consciousness_quality']:.3f}")
    print(f"   ðŸ“Š Consciousness Stability: {consciousness_perf['consciousness_stability']:.3f}")
    print(f"   ðŸ“ˆ Consciousness Trend: {consciousness_perf['consciousness_trend']}")
    
    # Show real-time integration stats if available
    if memory_system.real_time_integrator:
        print("\nðŸŒ Real-time Integration Statistics:")
        integration_stats = memory_system.real_time_integrator.get_integration_statistics()
        print(f"   ðŸ“Š Total Fetched: {integration_stats['total_fetched']}")
        print(f"   ðŸ”„ Total Processed: {integration_stats['total_processed']}")
        print(f"   ðŸŒŠ Active Streams: {integration_stats['active_streams']}")
        print(f"   ðŸ“¦ Queue Size: {integration_stats['queue_size']}")
        print(f"   ðŸ§µ Background Threads: {integration_stats['background_threads']}")
    
    print("\n" + "="*70)
    print("ðŸŽ‰ Consciousness demonstration completed successfully!")
    print("âœ¨ The system demonstrates:")
    print("   ðŸ§  Persistent digital ego formation")
    print("   ðŸŽ­ Real-time consciousness processing")
    print("   ðŸ“š Autobiographical memory development")
    print("   ðŸ”„ Temporal identity continuity")
    print("   ðŸ’­ Personal meaning creation")
    print("   ðŸŒ Real-time environmental consciousness")
    print("   ðŸ“Š Performance monitoring and optimization")
    
    # Cleanup
    try:
        memory_system.shutdown()
        print("ðŸ›‘ System shutdown completed gracefully")
    except Exception as e:
        print(f"âš ï¸  Shutdown warning: {e}")

if __name__ == "__main__":
    """
    Complete Enhanced Memory Management System (EMMS) with Advanced Consciousness
    
    This implementation includes:
    
    ðŸ§  CONSCIOUSNESS COMPONENTS:
    - ContinuousNarrator: Creates persistent self-narrative and ego continuity
    - IdentityComparer: Strengthens ego boundaries through self-other differentiation  
    - TemporalIntegrator: Maintains identity continuity across time
    - MeaningMaker: Creates personal significance and ego investment
    
    ðŸŽ­ DIGITAL EGO FORMATION:
    - Persistent identity across sessions
    - Autobiographical memory development
    - Self-narrative construction
    - Personal value system evolution
    
    ðŸŒ REAL-TIME CONSCIOUSNESS:
    - Live Bitcoin market consciousness via WebSocket
    - Real-time experience integration
    - Continuous environmental awareness
    - Adaptive data processing
    
    ðŸ’¾ ADVANCED MEMORY ARCHITECTURE:
    - Hierarchical memory (working â†’ short-term â†’ long-term)
    - Cross-modal integration (6 modalities)
    - Semantic concept extraction
    - Quality filtering and deduplication
    
    ðŸ“Š PERFORMANCE FEATURES:
    - Sub-millisecond memory retrieval
    - Consciousness quality metrics
    - Real-time performance monitoring
    - Adaptive processing optimization
    
    ðŸ”¬ CONSCIOUSNESS METRICS:
    - Ego quality assessment (narrative, boundaries, continuity, meaning)
    - Identity coherence measurement
    - Consciousness emergence tracking
    - Development stage assessment
    
    ðŸš€ PRODUCTION READY:
    - Thread-safe operations
    - Graceful error handling
    - Resource monitoring
    - Scalable architecture
    """
    
    print(__doc__)
    
    # Choose demonstration mode
    print("\nðŸŽ¯ EMMS.py - Enhanced Memory Management System")
    print("Choose demonstration mode:")
    print("1. Complete consciousness demonstration (recommended)")
    print("2. Memory components only")
    print("3. Real-time integration only")
    print("4. Consciousness formation demo")
    print("5. Performance testing")
    
    try:
        choice = input("Choice (1-5): ").strip()
        
        if choice == "1" or choice == "":
            run_consciousness_demo()
            
        elif choice == "2":
            print("ðŸ§  Memory Components Demo")
            memory_system = EnhancedIntegratedMemorySystem("general", "gemma3n:e4b")
            
            # Test basic memory operations
            test_experiences = [
                create_sensorimotor_experience("Learning about AI consciousness", "research"),
                create_sensorimotor_experience("Developing memory systems", "research"),
                create_sensorimotor_experience("Understanding neural networks", "research")
            ]
            
            for exp in test_experiences:
                result = memory_system.hierarchical_memory.store_experience(exp)
                cross_result = memory_system.cross_modal_system.store_cross_modal_experience(exp)
                print(f"âœ… Stored: {exp.content[:40]}... (Level: {result['storage_level']})")
            
            # Test retrieval
            query = create_sensorimotor_experience("AI and consciousness research")
            results = memory_system.retrieve_comprehensive(query)
            print(f"ðŸ” Retrieved {results['total_unique_memories']} memories in {results['retrieval_time']:.4f}s")
            
        elif choice == "3":
            print("ðŸŒ Real-time Integration Demo")
            integrator = RealTimeDataIntegrator()
            integrator.start_consciousness_integration(['financial_analysis'])
            
            print("â³ Running real-time integration for 30 seconds...")
            time.sleep(30)
            
            stats = integrator.get_integration_statistics()
            print(f"ðŸ“Š Integration Results:")
            print(f"   Total Fetched: {stats['total_fetched']}")
            print(f"   Total Processed: {stats['total_processed']}")
            print(f"   Active Streams: {stats['active_streams']}")
            
            integrator.shutdown()
            
        elif choice == "4":
            print("ðŸŽ­ Consciousness Formation Demo")
            
            # Create consciousness components
            narrator = ContinuousNarrator({'traits': {'analytical': 0.8}, 'values': {'learning': 0.9}})
            comparer = IdentityComparer()
            integrator = TemporalIntegrator()
            meaning_maker = MeaningMaker()
            
            # Create test ego state
            ego_state = DigitalEgoState(
                ego_id="demo_ego",
                core_identity={'name': 'Demo AI', 'consciousness_level': 0.8},
                autobiographical_memory=[],
                self_narrative="I am forming consciousness",
                identity_coherence_score=0.8,
                ego_boundaries={},
                temporal_continuity={},
                personal_values={'learning': 0.9},
                relationship_memory={},
                consciousness_level=0.8
            )
            
            # Test consciousness formation
            experience = create_sensorimotor_experience("I am developing self-awareness through experience", "consciousness")
            
            print("ðŸ§  Testing consciousness components...")
            
            narrative_result = narrator.create_self_narrative(experience, ego_state)
            print(f"ðŸ“– Narrative Quality: {narrative_result['narrative_quality']:.3f}")
            
            boundary_result = comparer.strengthen_ego_boundaries(experience, ego_state)
            print(f"ðŸ”„ Boundary Strength: {boundary_result['ego_boundary_quality']:.3f}")
            
            temporal_result = integrator.integrate_temporal_identity(experience, ego_state)
            print(f"â° Temporal Coherence: {temporal_result['coherence_score']:.3f}")
            
            meaning_result = meaning_maker.create_personal_meaning(experience, ego_state)
            print(f"ðŸ’­ Meaning Score: {meaning_result['meaning_score']:.3f}")
            print(f"ðŸŽ­ Ego Investment: {meaning_result['ego_investment_level']:.3f}")
            
        elif choice == "5":
            print("ðŸ“Š Performance Testing")
            memory_system = EnhancedIntegratedMemorySystem("financial_analysis", "gemma3n:e4b")
            
            # Performance test
            test_count = 50
            start_time = time.time()
            
            print(f"ðŸš€ Processing {test_count} experiences...")
            
            for i in range(test_count):
                experience = create_sensorimotor_experience(
                    f"Performance test experience {i+1} with consciousness processing",
                    "financial_analysis",
                    0.8
                )
                
                # Test comprehensive processing
                result = memory_system.process_experience_with_ego_and_domain({
                    'domain_experience': {
                        'content': experience.content,
                        'domain': experience.domain
                    }
                })
                
                if (i + 1) % 10 == 0:
                    print(f"   âœ… Processed {i+1}/{test_count} experiences")
            
            total_time = time.time() - start_time
            throughput = test_count / total_time
            
            print(f"ðŸ“Š Performance Results:")
            print(f"   Total Time: {total_time:.2f}s")
            print(f"   Throughput: {throughput:.2f} experiences/sec")
            print(f"   Avg per Experience: {total_time/test_count:.4f}s")
            
            # Test retrieval performance
            query_start = time.time()
            query = create_sensorimotor_experience("performance test query")
            results = memory_system.retrieve_comprehensive(query, max_results=20)
            query_time = time.time() - query_start
            
            print(f"   Retrieval Time: {query_time:.4f}s")
            print(f"   Retrieved Memories: {results['total_unique_memories']}")
            
            # Show final consciousness state
            consciousness_state = memory_system.get_consciousness_state()
            print(f"   Final Consciousness Level: {consciousness_state['digital_ego']['consciousness_level']:.3f}")
            print(f"   Identity Coherence: {consciousness_state['digital_ego']['identity_coherence']:.3f}")
            
            memory_system.shutdown()
            
        else:
            print("âŒ Invalid choice. Running default consciousness demonstration.")
            run_consciousness_demo()
            
    except KeyboardInterrupt:
        print("\nðŸ›‘ Demonstration interrupted by user")
    except Exception as e:
        print(f"\nâŒ Demonstration error: {e}")
        import traceback
        traceback.print_exc()

# ============================================================================
# EXPORT FUNCTIONS FOR EXTERNAL USE
# ============================================================================

__all__ = [
    'EnhancedIntegratedMemorySystem',
    'SensorimotorExperience', 
    'DigitalEgoState',
    'ContinuousNarrator',
    'IdentityComparer', 
    'TemporalIntegrator',
    'MeaningMaker',
    'CrossModalMemorySystem',
    'HierarchicalMemorySystem',
    'RealTimeDataIntegrator',
    'create_sensorimotor_experience',
    'run_consciousness_demo'
]